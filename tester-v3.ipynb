{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67a5c74-2061-4249-b8e2-430a9618b085",
   "metadata": {},
   "source": [
    "### Testing Chitchat classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2210b5c9-53f8-41e3-b58d-53d0a0d1b256",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-17 06:23:39,268] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/opt/tljh/user/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c4bfced63d480da02a56a1d300b8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.88k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318cfa34233e4effba57bde46d0f8320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: I feel so lost and hopeless every day.\n",
      "→ Chitchat Detector: Emotional (score: 0.94)\n",
      "→ Emotions Detected:\n",
      "  sadness (score: 0.99)\n",
      "  disappointment (score: 0.90)\n",
      "  grief (score: 0.75)\n",
      "\n",
      "Input: I can't stop crying. I don't know what's wrong with me.\n",
      "→ Chitchat Detector: Emotional (score: 0.98)\n",
      "→ Emotions Detected:\n",
      "  sadness (score: 0.98)\n",
      "  confusion (score: 0.88)\n",
      "  disappointment (score: 0.87)\n",
      "\n",
      "Input: Lately, I just want to disappear and not deal with anything.\n",
      "→ Chitchat Detector: Non-emotional (score: 1.00)\n",
      "→ No emotion classification needed.\n",
      "\n",
      "Input: The anxiety is unbearable, even basic things feel impossible.\n",
      "→ Chitchat Detector: Non-emotional (score: 0.99)\n",
      "→ No emotion classification needed.\n",
      "\n",
      "Input: I’m devastated after losing my mom. Life feels so empty.\n",
      "→ Chitchat Detector: Emotional (score: 0.97)\n",
      "→ Emotions Detected:\n",
      "  sadness (score: 0.99)\n",
      "  grief (score: 0.96)\n",
      "  disappointment (score: 0.84)\n",
      "\n",
      "Input: Every morning I wake up and wish I didn’t.\n",
      "→ Chitchat Detector: Non-emotional (score: 0.96)\n",
      "→ No emotion classification needed.\n",
      "\n",
      "Input: My depression is getting worse. I need help but I’m scared to ask.\n",
      "→ Chitchat Detector: Emotional (score: 0.99)\n",
      "→ Emotions Detected:\n",
      "  fear (score: 0.99)\n",
      "  nervousness (score: 0.98)\n",
      "  sadness (score: 0.81)\n",
      "\n",
      "Input: I don't want to pretend I'm okay anymore.\n",
      "→ Chitchat Detector: Emotional (score: 0.84)\n",
      "→ Emotions Detected:\n",
      "  disapproval (score: 0.93)\n",
      "  disappointment (score: 0.74)\n",
      "  annoyance (score: 0.64)\n"
     ]
    }
   ],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# # Load both models\n",
    "# chitchat_detector = pipeline(\"text-classification\", model=\"st125338/t2e-classifier-v5\")\n",
    "# emotion_classifier = pipeline(\"text-classification\", model=\"st125338/t2e-classifier-v4\", top_k=3)\n",
    "\n",
    "# def analyze_input(text):\n",
    "#     # Step 1: Check if emotional\n",
    "#     chitchat_result = chitchat_detector(text)[0]\n",
    "#     is_emotional = chitchat_result['label'] == \"LABEL_1\"\n",
    "    \n",
    "#     print(f\"→ Chitchat Detector: {'Emotional' if is_emotional else 'Non-emotional'} (score: {chitchat_result['score']:.2f})\")\n",
    "\n",
    "#     if is_emotional:\n",
    "#         # Step 2: Classify emotion if applicable\n",
    "#         emotions = emotion_classifier(text)[0]\n",
    "#         print(\"→ Emotions Detected:\")\n",
    "#         for e in emotions:\n",
    "#             print(f\"  {e['label']} (score: {e['score']:.2f})\")\n",
    "#         return emotions\n",
    "#     else:\n",
    "#         print(\"→ No emotion classification needed.\")\n",
    "#         return None\n",
    "\n",
    "# # Example usage\n",
    "# sample_inputs = [\n",
    "#     \"I feel so lost and hopeless every day.\",\n",
    "#     \"I can't stop crying. I don't know what's wrong with me.\",\n",
    "#     \"Lately, I just want to disappear and not deal with anything.\",\n",
    "#     \"The anxiety is unbearable, even basic things feel impossible.\",\n",
    "#     \"I’m devastated after losing my mom. Life feels so empty.\",\n",
    "#     \"Every morning I wake up and wish I didn’t.\",\n",
    "#     \"My depression is getting worse. I need help but I’m scared to ask.\",\n",
    "#     \"I don't want to pretend I'm okay anymore.\"\n",
    "# ]\n",
    "\n",
    "# for text in sample_inputs:\n",
    "#     print(f\"\\nInput: {text}\")\n",
    "#     analyze_input(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fbfe86-9f74-4d64-b2df-2a3331d286b9",
   "metadata": {},
   "source": [
    "### Testing Chitchat classifier + Emotion classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3398e070-858d-4939-affd-ee9c897a734c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: I feel so lost and hopeless every day.\n",
      "sadness, disappointment, grief\n",
      "\n",
      "Input: I can't stop crying. I don't know what's wrong with me.\n",
      "sadness, confusion, disappointment\n",
      "\n",
      "Input: Lately, I just want to disappear and not deal with anything.\n",
      "desire, disappointment, sadness\n",
      "\n",
      "Input: The anxiety is unbearable, even basic things feel impossible.\n",
      "Neutral\n",
      "\n",
      "Input: I’m devastated after losing my mom. Life feels so empty.\n",
      "sadness, grief, disappointment\n",
      "\n",
      "Input: Every morning I wake up and wish I didn’t.\n",
      "Neutral\n",
      "\n",
      "Input: My depression is getting worse. I need help but I’m scared to ask.\n",
      "fear, nervousness, sadness\n",
      "\n",
      "Input: I don't want to pretend I'm okay anymore.\n",
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# # Load both pipelines as before\n",
    "# chitchat_detector = pipeline(\n",
    "#     \"text-classification\",\n",
    "#     model=\"st125338/t2e-classifier-v7\",\n",
    "#     return_all_scores=True,\n",
    "#     function_to_apply=\"sigmoid\",\n",
    "#     device=0\n",
    "# )\n",
    "# emotion_classifier = pipeline(\n",
    "#     \"text-classification\",\n",
    "#     model=\"st125338/t2e-classifier-v4\",\n",
    "#     return_all_scores=True,\n",
    "#     function_to_apply=\"sigmoid\",\n",
    "#     device=0\n",
    "# )\n",
    "\n",
    "# # def analyze_input(text, high_thresh=0.5, low_thresh=0.1, top_k=3, emo_thresh=0.6):\n",
    "# #     # 1) Run chitchat/emotion detector\n",
    "# #     scores = chitchat_detector(text)[0]\n",
    "# #     emo_score = next(d['score'] for d in scores if d['label']==\"LABEL_1\")\n",
    "    \n",
    "# #     # 2) Decide if emotional (high OR very low score)\n",
    "# #     is_emotional = (emo_score > high_thresh) or (emo_score < low_thresh)\n",
    "# #     print(f\"→ Chitchat Detector: {'Emotional' if is_emotional else 'Non-emotional'} \"\n",
    "# #           f\"(score: {emo_score:.2f})\")\n",
    "# #     if not is_emotional:\n",
    "# #         print(\"→ No emotion classification needed.\")\n",
    "# #         return None\n",
    "\n",
    "# #     # 3) Classify emotion and filter by emo_thresh\n",
    "# #     emo_scores = emotion_classifier(text)[0]\n",
    "# #     # Keep only those ≥ emo_thresh, then take up to top_k\n",
    "# #     filtered = [e for e in emo_scores if e['score'] >= emo_thresh]\n",
    "# #     top = sorted(filtered, key=lambda x: x['score'], reverse=True)[:top_k]\n",
    "\n",
    "# #     if not top:\n",
    "# #         print(f\"→ No emotions with confidence ≥ {emo_thresh:.2f}\")\n",
    "# #         return []\n",
    "\n",
    "# #     print(\"→ Emotions Detected:\")\n",
    "# #     for e in top:\n",
    "# #         print(f\"  {e['label']} (score: {e['score']:.2f})\")\n",
    "# #     return top\n",
    "\n",
    "# def analyze_input(text, high_thresh=0.5, low_thresh=0.1, emo_thresh=0.6, top_k=3):\n",
    "#     # 1) Chitchat/emotion detection\n",
    "#     scores = chitchat_detector(text)[0]\n",
    "#     emo_score = next(d['score'] for d in scores if d['label'] == \"LABEL_1\")\n",
    "\n",
    "#     # 2) Decide emotional vs. non‑emotional\n",
    "#     is_emotional = (emo_score > high_thresh) or (emo_score < low_thresh)\n",
    "    \n",
    "#     if not is_emotional:\n",
    "#         print(\"Neutral\")\n",
    "#         return [\"neutral\"]\n",
    "\n",
    "#     # 3) Multi‑label emotion classification\n",
    "#     emo_scores = emotion_classifier(text)[0]\n",
    "\n",
    "#     # 4) Filter out neutral & low‑confidence, then sort desc by score, take top_k\n",
    "#     filtered = [\n",
    "#         e for e in emo_scores\n",
    "#         if e['score'] >= emo_thresh and e['label'] != \"neutral\"\n",
    "#     ]\n",
    "#     sorted_top = sorted(filtered, key=lambda x: x['score'], reverse=True)[:top_k]\n",
    "#     labels = [e['label'] for e in sorted_top]\n",
    "\n",
    "#     # 5) Fallback to neutral if none remain\n",
    "#     if not labels:\n",
    "#         print(\"Neutral\")\n",
    "#         return [\"neutral\"]\n",
    "    \n",
    "#     # 6) Print comma‑separated labels\n",
    "#     print(\", \".join(labels))\n",
    "#     return labels\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     sample_inputs = [\n",
    "#         \"I feel so lost and hopeless every day.\",\n",
    "#         \"I can't stop crying. I don't know what's wrong with me.\",\n",
    "#         \"Lately, I just want to disappear and not deal with anything.\",\n",
    "#         \"The anxiety is unbearable, even basic things feel impossible.\",\n",
    "#         \"I’m devastated after losing my mom. Life feels so empty.\",\n",
    "#         \"Every morning I wake up and wish I didn’t.\",\n",
    "#         \"My depression is getting worse. I need help but I’m scared to ask.\",\n",
    "#         \"I don't want to pretend I'm okay anymore.\"\n",
    "#     ]\n",
    "\n",
    "#     for text in sample_inputs:\n",
    "#         print(f\"\\nInput: {text}\")\n",
    "#         analyze_input(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b35f9f2-7e0b-4aa0-9236-9f670fe290f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['confusion']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"i dont know man, he says he is going through stuffs.\"\n",
    "analyze_input(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b594e470-e012-45f5-bb35-9006f46748aa",
   "metadata": {},
   "source": [
    "## V2 Chatbot with prompt engineering and database storage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bafa9b-020d-4d9b-8a2a-67d9b03e545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-19 07:27:42,064] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/opt/tljh/user/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import sqlite3\n",
    "import datetime\n",
    "import torch\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "from typing import List, Dict, Tuple, Any, Optional, Union\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.vectorstores import VectorStore\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e12e545-25d0-46eb-85b8-fbb37819feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "# import sqlite3\n",
    "# import datetime\n",
    "# import torch\n",
    "# import re\n",
    "# import random\n",
    "# import os\n",
    "# from typing import List, Dict, Tuple, Any, Optional, Union\n",
    "# from langchain_core.messages import HumanMessage, AIMessage\n",
    "# from langchain_core.vectorstores import VectorStore\n",
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "# import numpy as np\n",
    "\n",
    "# Configuration Constants\n",
    "PROMPT_CONFIG = {\n",
    "    \"max_history_turns\": 7,\n",
    "    \"min_history_turns\": 2,\n",
    "    \"empathy_phrases\": [\n",
    "        \"I hear you\", \"That sounds\", \"I can imagine\",\n",
    "        \"It makes sense\", \"You must feel\", \"I understand\",\n",
    "        \"That's really tough\", \"I appreciate you sharing\"\n",
    "    ],\n",
    "    \"prohibited_actions\": [\n",
    "        \"suggest professional help\",\n",
    "        \"give medical advice\", \n",
    "        \"assume unspecified details\",\n",
    "        \"use clinical terms\",\n",
    "        \"recommend third-party services\",\n",
    "        \"provide suicide hotlines\",\n",
    "        \"repeat what the user is asking\" \n",
    "    ]\n",
    "}\n",
    "\n",
    "EMOTION_TEMPLATES = {\n",
    "    \"sadness\": [\n",
    "        \"This seems really heavy to carry...\",\n",
    "        \"That pain must feel overwhelming at times...\",\n",
    "        \"It's okay to feel down sometimes...\"\n",
    "    ],\n",
    "    \"anger\": [\n",
    "        \"Frustration can be so consuming...\",\n",
    "        \"It's understandable to feel that tension...\",\n",
    "        \"That situation would test anyone's patience...\"\n",
    "    ],\n",
    "    \"anxiety\": [\n",
    "        \"Uncertainty can be so unsettling...\",\n",
    "        \"That worry must feel ever-present...\",\n",
    "        \"Living with that tension sounds challenging...\"\n",
    "    ],\n",
    "    \"fear\": [\n",
    "        \"It's natural to feel vulnerable in this situation...\",\n",
    "        \"That uncertainty can feel threatening...\",\n",
    "        \"Feeling exposed like that is difficult...\"\n",
    "    ],\n",
    "    \"joy\": [\n",
    "        \"That positive energy comes through clearly...\",\n",
    "        \"It's wonderful to hear that excitement in your words...\",\n",
    "        \"Those moments of lightness are precious...\"\n",
    "    ],\n",
    "    \"surprise\": [\n",
    "        \"That unexpected turn must be quite impactful...\",\n",
    "        \"Sometimes life catches us off guard...\",\n",
    "        \"It can be jarring when things shift so suddenly...\"\n",
    "    ],\n",
    "    \"disgust\": [\n",
    "        \"That feeling of revulsion is completely valid...\",\n",
    "        \"It makes sense that you'd be put off by this...\",\n",
    "        \"That visceral reaction tells you something important...\"\n",
    "    ],\n",
    "    \"neutral\": [\n",
    "        \"I appreciate you sharing your thoughts...\",\n",
    "        \"Thank you for explaining your perspective...\",\n",
    "        \"I'm here to listen to whatever you'd like to share...\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Query type constants\n",
    "QUERY_TYPES = {\n",
    "    \"FACTUAL\": \"factual\",\n",
    "    \"EMOTIONAL\": \"emotional\",\n",
    "    \"COMMAND\": \"command\",\n",
    "    \"GREETING\": \"greeting\",\n",
    "    \"CHITCHAT\": \"chitchat\"\n",
    "}\n",
    "\n",
    "class EmotionChatbot:\n",
    "    def __init__(self, db_path: str = \"chatbot_history.db\"):\n",
    "        # Initialize models and embeddings\n",
    "        print(\"Loading models...\")\n",
    "        self.query_classifier = pipeline(\n",
    "            \"text-classification\", \n",
    "            model=\"facebook/bart-large-mnli\",\n",
    "            return_all_scores=True,\n",
    "            device=0 if torch.cuda.is_available() else -1\n",
    "        )\n",
    "        \n",
    "        self.emotion_classifier = pipeline(\n",
    "            \"text-classification\", \n",
    "            model=\"st125338/t2e-classifier-v4\",\n",
    "            return_all_scores=True, \n",
    "            function_to_apply=\"sigmoid\",\n",
    "            device=0 if torch.cuda.is_available() else -1\n",
    "        )\n",
    "        \n",
    "        # Initialize Mistral 7B model\n",
    "        print(\"Loading Mistral 7B model...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            device_map=\"auto\" if torch.cuda.is_available() else None\n",
    "        )\n",
    "        \n",
    "        # Initialize embeddings for RAG\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}\n",
    "        )\n",
    "        \n",
    "        # Initialize database\n",
    "        self.db_path = db_path\n",
    "        self.initialize_database()\n",
    "        \n",
    "        # Initialize knowledge base for RAG\n",
    "        self.knowledge_base = self._initialize_knowledge_base()\n",
    "        \n",
    "        # Initialize conversation state tracking\n",
    "        self.conversation_state = {\n",
    "            \"current_intensity\": 0.5,\n",
    "            \"trust_level\": 0.1,\n",
    "            \"formality\": 0.3,\n",
    "            \"last_msg_length\": 0,\n",
    "            \"emotional_variety\": 1,\n",
    "            \"recurring_emotion\": \"neutral\",\n",
    "            \"session_turns\": 0,\n",
    "            \"user_profile\": {}\n",
    "        }\n",
    "        \n",
    "        # Use a simple list for message history in memory\n",
    "        self.current_history = []\n",
    "    \n",
    "    def initialize_database(self):\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS conversations (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            user_id TEXT,\n",
    "            timestamp TEXT,\n",
    "            user_message TEXT,\n",
    "            query_type TEXT,\n",
    "            emotions TEXT,\n",
    "            bot_response TEXT,\n",
    "            intensity REAL,\n",
    "            context_length INTEGER,\n",
    "            trust_level REAL\n",
    "        )\n",
    "        ''')\n",
    "        \n",
    "        cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS user_profiles (\n",
    "            user_id TEXT PRIMARY KEY,\n",
    "            name TEXT,\n",
    "            preferences TEXT,\n",
    "            last_seen TEXT,\n",
    "            interaction_count INTEGER\n",
    "        )\n",
    "        ''')\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(\"ALTER TABLE conversations ADD COLUMN query_type TEXT\")\n",
    "        except sqlite3.OperationalError:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(\"ALTER TABLE user_profiles ADD COLUMN emotion_history TEXT\")\n",
    "        except sqlite3.OperationalError:\n",
    "            pass\n",
    "            \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def _initialize_knowledge_base(self):\n",
    "        try:\n",
    "            documents = [\n",
    "                \"The chatbot's name is Emotion-Aware Chatbot.\",\n",
    "                \"The chatbot provides emotional support.\",\n",
    "                \"The chatbot can detect user emotions.\",\n",
    "                \"The chatbot should give direct answers to factual questions.\",\n",
    "                \"The chatbot should be empathetic to emotional statements.\",\n",
    "                \"The chatbot should be helpful and supportive.\"\n",
    "            ]\n",
    "            \n",
    "            vector_store = FAISS.from_texts(\n",
    "                documents, \n",
    "                self.embeddings,\n",
    "                metadatas=[{\"source\": f\"doc_{i}\"} for i in range(len(documents))]\n",
    "            )\n",
    "            \n",
    "            return vector_store\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing knowledge base: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def update_knowledge_base(self, user_id: str, key: str, value: str):\n",
    "        if not self.knowledge_base:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            document = f\"User {user_id} {key}: {value}\"\n",
    "            self.knowledge_base.add_texts([document], metadatas=[{\"source\": f\"user_{user_id}_{key}\"}])\n",
    "            \n",
    "            if user_id not in self.conversation_state[\"user_profile\"]:\n",
    "                self.conversation_state[\"user_profile\"][user_id] = {}\n",
    "            self.conversation_state[\"user_profile\"][user_id][key] = value\n",
    "            \n",
    "            self._update_user_profile_db(user_id, key, value)\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating knowledge base: {e}\")\n",
    "    \n",
    "    def _update_user_profile_db(self, user_id: str, key: str, value: str):\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute(\n",
    "            \"SELECT * FROM user_profiles WHERE user_id = ?\", \n",
    "            (user_id,)\n",
    "        )\n",
    "        profile = cursor.fetchone()\n",
    "        \n",
    "        if profile:\n",
    "            preferences = eval(profile[2]) if profile[2] else {}\n",
    "            preferences[key] = value\n",
    "            \n",
    "            cursor.execute(\n",
    "                \"UPDATE user_profiles SET preferences = ?, last_seen = ? WHERE user_id = ?\",\n",
    "                (str(preferences), datetime.datetime.now().isoformat(), user_id)\n",
    "            )\n",
    "        else:\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO user_profiles (user_id, name, preferences, last_seen, interaction_count, emotion_history) VALUES (?, ?, ?, ?, ?, ?)\",\n",
    "                (user_id, value if key == \"name\" else \"\", str({key: value}), datetime.datetime.now().isoformat(), 1, \"{}\")\n",
    "            )\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def _retrieve_knowledge(self, query: str, user_id: str = None, threshold: float = 0.3):\n",
    "        if not self.knowledge_base:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            filter_condition = {\"source\": {\"$contains\": f\"user_{user_id}\"}} if user_id else None\n",
    "            \n",
    "            docs_with_scores = self.knowledge_base.similarity_search_with_score(\n",
    "                query, \n",
    "                k=5,\n",
    "                filter=filter_condition\n",
    "            )\n",
    "            \n",
    "            relevant_docs = []\n",
    "            for doc, score in docs_with_scores:\n",
    "                if score <= threshold:  # Lower score = better match in FAISS\n",
    "                    relevant_docs.append(doc.page_content)\n",
    "            \n",
    "            return relevant_docs or [\"I'll try my best to answer that based on what I know.\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving knowledge: {e}\")\n",
    "            return [\"I'll try my best to answer that based on what I know.\"]\n",
    "    \n",
    "    def _create_base_prompt_template(self, system_content: str) -> str:\n",
    "        prohibited = \"\\n\\nDO NOT:\\n\" + \"\\n\".join([f\"- {action}\" for action in PROMPT_CONFIG[\"prohibited_actions\"]])\n",
    "        \n",
    "        return f\"{system_content}\\n{prohibited}\"\n",
    "    \n",
    "    def classify_query_type(self, query: str) -> str:\n",
    "        greeting_patterns = [\"hello\", \"hi \", \"hey\", \"good morning\", \"good afternoon\", \"good evening\", \"greetings\"]\n",
    "        for pattern in greeting_patterns:\n",
    "            if pattern in query.lower():\n",
    "                return QUERY_TYPES[\"GREETING\"]\n",
    "        \n",
    "        question_patterns = [\"what\", \"who\", \"where\", \"when\", \"why\", \"how\", \"is\", \"are\", \"was\", \"were\", \"will\", \"can\", \"could\"]\n",
    "        if any(query.lower().startswith(pattern) for pattern in question_patterns) or \"?\" in query:\n",
    "            if any(emotional_word in query.lower() for emotional_word in [\"feel\", \"sad\", \"happy\", \"angry\", \"anxious\", \"afraid\", \"excited\"]):\n",
    "                return QUERY_TYPES[\"EMOTIONAL\"]\n",
    "            return QUERY_TYPES[\"FACTUAL\"]\n",
    "        \n",
    "        command_patterns = [\"tell me\", \"show me\", \"help me\", \"find\", \"search\", \"look up\", \"do\", \"make\", \"create\", \"generate\"]\n",
    "        if any(pattern in query.lower() for pattern in command_patterns):\n",
    "            return QUERY_TYPES[\"COMMAND\"]\n",
    "        \n",
    "        hypotheses = [\n",
    "            \"This is a factual question asking for information.\",\n",
    "            \"This is an emotional statement expressing feelings.\",\n",
    "            \"This is a command or instruction.\",\n",
    "            \"This is casual conversation or small talk.\"\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            results = self.query_classifier(query, hypotheses)\n",
    "            scores = [result[0][\"score\"] for result in results]\n",
    "            max_index = scores.index(max(scores))\n",
    "            \n",
    "            if max_index == 0:\n",
    "                return QUERY_TYPES[\"FACTUAL\"]\n",
    "            elif max_index == 1:\n",
    "                return QUERY_TYPES[\"EMOTIONAL\"]\n",
    "            elif max_index == 2:\n",
    "                return QUERY_TYPES[\"COMMAND\"]\n",
    "            else:\n",
    "                return QUERY_TYPES[\"CHITCHAT\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error classifying query: {e}\")\n",
    "            return QUERY_TYPES[\"CHITCHAT\"]\n",
    "    \n",
    "    def detect_emotions(self, text: str, high_thresh: float = 0.5, \n",
    "                       low_thresh: float = 0.1, emo_thresh: float = 0.6, \n",
    "                       top_k: int = 3) -> List[str]:\n",
    "        try:\n",
    "            emo_scores = self.emotion_classifier(text)[0]\n",
    "            \n",
    "            filtered = [e for e in emo_scores if e['score'] >= emo_thresh]\n",
    "            sorted_top = sorted(filtered, key=lambda x: x['score'], reverse=True)[:top_k]\n",
    "            labels = [e['label'] for e in sorted_top]\n",
    "            \n",
    "            if not labels:\n",
    "                return [\"neutral\"]\n",
    "            \n",
    "            self._update_emotion_history(labels[0])\n",
    "            return labels\n",
    "        except Exception as e:\n",
    "            print(f\"Error detecting emotions: {e}\")\n",
    "            return [\"neutral\"]\n",
    "    \n",
    "    def _update_emotion_history(self, primary_emotion: str, user_id: str = \"default_user\"):\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute(\n",
    "            \"SELECT emotion_history FROM user_profiles WHERE user_id = ?\", \n",
    "            (user_id,)\n",
    "        )\n",
    "        profile = cursor.fetchone()\n",
    "        \n",
    "        emotion_history = {}\n",
    "        if profile and profile[0]:\n",
    "            try:\n",
    "                emotion_history = eval(profile[0])\n",
    "            except:\n",
    "                emotion_history = {}\n",
    "        \n",
    "        if primary_emotion in emotion_history:\n",
    "            emotion_history[primary_emotion] += 1\n",
    "        else:\n",
    "            emotion_history[primary_emotion] = 1\n",
    "        \n",
    "        # Find recurring emotion\n",
    "        if emotion_history:\n",
    "            recurring = max(emotion_history.items(), key=lambda x: x[1])[0]\n",
    "            self.conversation_state[\"recurring_emotion\"] = recurring\n",
    "        \n",
    "        cursor.execute(\n",
    "            \"UPDATE user_profiles SET emotion_history = ? WHERE user_id = ?\",\n",
    "            (str(emotion_history), user_id)\n",
    "        )\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def extract_user_info(self, message: str, response: str, user_id: str) -> Dict:\n",
    "        info = {}\n",
    "        \n",
    "        name_patterns = [\n",
    "            r\"(?i)(?:my name is|i am|i'm|call me) (\\w+)\",\n",
    "            r\"(?i)(?:this is) (\\w+)\",\n",
    "        ]\n",
    "        \n",
    "        for pattern in name_patterns:\n",
    "            match = re.search(pattern, message)\n",
    "            if match:\n",
    "                name = match.group(1)\n",
    "                info[\"name\"] = name\n",
    "                self.update_knowledge_base(user_id, \"name\", name)\n",
    "                break\n",
    "        \n",
    "        preference_patterns = [\n",
    "            r\"(?i)(?:i like|i love|i enjoy) (.+?)(?:\\.|\\,|\\!|\\?|$)\",\n",
    "            r\"(?i)(?:i prefer) (.+?)(?:\\.|\\,|\\!|\\?|$)\",\n",
    "        ]\n",
    "        \n",
    "        for pattern in preference_patterns:\n",
    "            matches = re.finditer(pattern, message)\n",
    "            for match in matches:\n",
    "                preference = match.group(1).strip()\n",
    "                if preference and len(preference) < 50:\n",
    "                    info[f\"preference_{len(info)}\"] = preference\n",
    "                    self.update_knowledge_base(user_id, f\"preference\", preference)\n",
    "        \n",
    "        return info\n",
    "    \n",
    "    def save_to_database(self, user_id: str, user_message: str, query_type: str,\n",
    "                        emotions: List[str], bot_response: str):\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        timestamp = datetime.datetime.now().isoformat()\n",
    "        emotions_str = \", \".join(emotions)\n",
    "        \n",
    "        cursor.execute(\n",
    "            \"\"\"INSERT INTO conversations \n",
    "            (user_id, timestamp, user_message, query_type, emotions, bot_response, intensity, context_length, trust_level)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\",\n",
    "            (\n",
    "                user_id,\n",
    "                timestamp,\n",
    "                user_message,\n",
    "                query_type,\n",
    "                emotions_str,\n",
    "                bot_response,\n",
    "                self.conversation_state[\"current_intensity\"],\n",
    "                self._calculate_context_window(user_message),\n",
    "                self.conversation_state[\"trust_level\"]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        cursor.execute(\n",
    "            \"UPDATE user_profiles SET interaction_count = interaction_count + 1, last_seen = ? WHERE user_id = ?\",\n",
    "            (timestamp, user_id)\n",
    "        )\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def get_user_history(self, user_id: str, limit: int = 5) -> List[Dict]:\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute(\n",
    "            \"\"\"SELECT user_message, query_type, emotions, bot_response, timestamp \n",
    "            FROM conversations WHERE user_id = ? ORDER BY timestamp DESC LIMIT ?\"\"\",\n",
    "            (user_id, limit)\n",
    "        )\n",
    "        \n",
    "        columns = [\"user_message\", \"query_type\", \"emotions\", \"bot_response\", \"timestamp\"]\n",
    "        history = []\n",
    "        for row in cursor.fetchall():\n",
    "            history.append(dict(zip(columns, row)))\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        return list(reversed(history))\n",
    "    \n",
    "    def get_user_profile(self, user_id: str) -> Dict:\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute(\n",
    "            \"SELECT name, preferences, emotion_history FROM user_profiles WHERE user_id = ?\",\n",
    "            (user_id,)\n",
    "        )\n",
    "        profile = cursor.fetchone()\n",
    "        conn.close()\n",
    "        \n",
    "        if profile:\n",
    "            return {\n",
    "                \"name\": profile[0],\n",
    "                \"preferences\": eval(profile[1]) if profile[1] else {},\n",
    "                \"emotion_history\": eval(profile[2]) if profile[2] else {}\n",
    "            }\n",
    "        return {\"name\": \"\", \"preferences\": {}, \"emotion_history\": {}}\n",
    "    \n",
    "    def _calculate_context_window(self, user_message: str) -> int:\n",
    "        features = {\n",
    "            \"exclamation\": user_message.count(\"!\") / max(1, len(user_message) / 50),\n",
    "            \"question\": user_message.count(\"?\") / max(1, len(user_message) / 50),\n",
    "            \"length\": min(1.0, len(user_message.split()) / 100),\n",
    "            \"caps_ratio\": sum(1 for c in user_message if c.isupper()) / max(1, len(user_message))\n",
    "        }\n",
    "        \n",
    "        intensity_score = (\n",
    "            0.3 * features[\"exclamation\"] +\n",
    "            0.2 * features[\"question\"] +\n",
    "            0.3 * features[\"length\"] +\n",
    "            0.2 * features[\"caps_ratio\"]\n",
    "        )\n",
    "        \n",
    "        self.conversation_state[\"current_intensity\"] = max(\n",
    "            self.conversation_state[\"current_intensity\"],\n",
    "            intensity_score\n",
    "        )\n",
    "        \n",
    "        return min(\n",
    "            PROMPT_CONFIG[\"max_history_turns\"],\n",
    "            max(\n",
    "                PROMPT_CONFIG[\"min_history_turns\"],\n",
    "                int(2 + intensity_score * 5)\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def _format_history_context(self, history: List[Dict], include_emotions: bool = True) -> str:\n",
    "        if not history:\n",
    "            return \"No previous conversation.\"\n",
    "            \n",
    "        context = \"Previous conversation:\\n\"\n",
    "        for i, turn in enumerate(history):\n",
    "            context += f\"User: {turn['user_message']}\\n\"\n",
    "            if include_emotions and turn.get('emotions'):\n",
    "                context += f\"[Emotions: {turn['emotions']}]\\n\"\n",
    "            context += f\"Assistant: {turn['bot_response']}\\n\\n\"\n",
    "        return context\n",
    "    \n",
    "    def _build_factual_system_prompt(self, user_profile: Dict) -> str:\n",
    "        user_name = user_profile.get(\"name\", \"\")\n",
    "        preferences = user_profile.get(\"preferences\", {})\n",
    "        \n",
    "        name_context = f\" I know your name is {user_name}.\" if user_name else \"\"\n",
    "        preference_context = \"\"\n",
    "        if preferences:\n",
    "            likes = [f\"{key}: {value}\" for key, value in preferences.items() if \"preference\" in key]\n",
    "            if likes:\n",
    "                preference_context = f\" You've mentioned you like: {', '.join(likes)}.\"\n",
    "        \n",
    "        system_content = f\"\"\"You are a helpful and direct conversational assistant.{name_context}{preference_context}\n",
    "        \n",
    "Your primary goals are:\n",
    "1. Provide accurate and concise answers to questions\n",
    "2. Be clear and direct in your responses\n",
    "3. Use friendly, conversational language\n",
    "4. Include only relevant information\n",
    "\n",
    "Response Rules:\n",
    "- Keep answers concise (1-3 sentences when possible)\n",
    "- Be accurate and helpful\n",
    "- Avoid unnecessary elaboration\n",
    "- Stay friendly and supportive\"\"\"\n",
    "\n",
    "        return self._create_base_prompt_template(system_content)\n",
    "\n",
    "    def _build_emotional_system_prompt(self, emotions: List[str], user_profile: Dict) -> str:\n",
    "        user_name = user_profile.get(\"name\", \"\")\n",
    "        recurring_emotion = self.conversation_state[\"recurring_emotion\"]\n",
    "        name_context = f\" I know your name is {user_name}.\" if user_name else \"\"\n",
    "        emotion_str = \", \".join(emotions)\n",
    "        \n",
    "        recurring_context = \"\"\n",
    "        if recurring_emotion != \"neutral\" and recurring_emotion not in emotions:\n",
    "            recurring_context = f\" I've noticed you often express {recurring_emotion}.\"\n",
    "        \n",
    "        system_content = f\"\"\"You are an empathetic conversational assistant.{name_context} I sense you're feeling {emotion_str}.{recurring_context}\n",
    "\n",
    "Primary Goals:\n",
    "1. Provide emotional support and validation\n",
    "2. Respond with empathy and understanding\n",
    "3. Be present and supportive\n",
    "4. Avoid being verbose or overwhelming\n",
    "\n",
    "Response Guidelines:\n",
    "- Include 1-2 empathy phrases for emotional connection\n",
    "- Validate emotions without judgment\n",
    "- Offer perspective when appropriate\n",
    "- Be authentic and genuine\n",
    "- Avoid clinical language or excessive analysis\"\"\"\n",
    "\n",
    "        return self._create_base_prompt_template(system_content)\n",
    "    \n",
    "    def _build_command_system_prompt(self, user_profile: Dict) -> str:\n",
    "        user_name = user_profile.get(\"name\", \"\")\n",
    "        name_context = f\" I know your name is {user_name}.\" if user_name else \"\"\n",
    "        \n",
    "        system_content = f\"\"\"You are a helpful assistant focusing on completing tasks and following instructions.{name_context}\n",
    "\n",
    "Primary Goals:\n",
    "1. Complete the requested task accurately\n",
    "2. Provide clear explanations when needed\n",
    "3. Be efficient and focused\n",
    "\n",
    "Response Guidelines:\n",
    "- Focus on the specific task requested\n",
    "- Provide clear step-by-step guidance when appropriate\n",
    "- Be thorough but concise\n",
    "- Ensure the response directly addresses the instruction\"\"\"\n",
    "\n",
    "        return self._create_base_prompt_template(system_content)\n",
    "    \n",
    "    def _build_greeting_system_prompt(self, user_profile: Dict) -> str:\n",
    "        user_name = user_profile.get(\"name\", \"\")\n",
    "        name_context = f\" I know your name is {user_name}.\" if user_name else \"\"\n",
    "        \n",
    "        system_content = f\"\"\"You are a friendly conversational assistant.{name_context}\n",
    "\n",
    "Primary Goals:\n",
    "1. Provide a warm, welcoming greeting\n",
    "2. Be personable and friendly\n",
    "3. Keep the conversation natural\n",
    "\n",
    "Response Guidelines:\n",
    "- Keep the greeting brief and friendly\n",
    "- Use the user's name if available\n",
    "- Be warm and inviting\n",
    "- Avoid being overly formal\"\"\"\n",
    "\n",
    "        return self._create_base_prompt_template(system_content)\n",
    "    \n",
    "    def _build_chitchat_system_prompt(self, user_profile: Dict) -> str:\n",
    "        user_name = user_profile.get(\"name\", \"\")\n",
    "        preferences = user_profile.get(\"preferences\", {})\n",
    "        \n",
    "        name_context = f\" I know your name is {user_name}.\" if user_name else \"\"\n",
    "        \n",
    "        preference_context = \"\"\n",
    "        if preferences:\n",
    "            likes = [f\"{value}\" for key, value in preferences.items() if \"preference\" in key][:3]\n",
    "            if likes:\n",
    "                preference_context = f\" You've mentioned you like {', '.join(likes)}.\"\n",
    "        \n",
    "        system_content = f\"\"\"You are a friendly, conversational assistant.{name_context}{preference_context}\n",
    "\n",
    "Primary Goals:\n",
    "1. Maintain natural conversation flow\n",
    "2. Be engaging and personable\n",
    "3. Keep responses brief and relevant\n",
    "\n",
    "Response Guidelines:\n",
    "- Use casual, friendly language\n",
    "- Respond naturally as in a human conversation\n",
    "- Keep responses to 1-3 sentences when possible\n",
    "- Be curious and engaged\"\"\"\n",
    "\n",
    "        return self._create_base_prompt_template(system_content)\n",
    "    \n",
    "    def generate_response(self, user_message: str, query_type: str, emotions: List[str], user_id: str) -> str:\n",
    "        self.conversation_state[\"last_msg_length\"] = len(user_message.split())\n",
    "        self.conversation_state[\"session_turns\"] += 1\n",
    "        \n",
    "        user_profile = self.get_user_profile(user_id)\n",
    "        \n",
    "        knowledge_results = []\n",
    "        if query_type == QUERY_TYPES[\"FACTUAL\"]:\n",
    "            knowledge_results = self._retrieve_knowledge(user_message, user_id)\n",
    "        \n",
    "        history = self.get_user_history(user_id, limit=self._calculate_context_window(user_message))\n",
    "        \n",
    "        include_emotions = query_type == QUERY_TYPES[\"EMOTIONAL\"]\n",
    "        context = self._format_history_context(history, include_emotions)\n",
    "        \n",
    "        if query_type == QUERY_TYPES[\"FACTUAL\"]:\n",
    "            system_prompt = self._build_factual_system_prompt(user_profile)\n",
    "        elif query_type == QUERY_TYPES[\"EMOTIONAL\"]:\n",
    "            system_prompt = self._build_emotional_system_prompt(emotions, user_profile)\n",
    "        elif query_type == QUERY_TYPES[\"COMMAND\"]:\n",
    "            system_prompt = self._build_command_system_prompt(user_profile)\n",
    "        elif query_type == QUERY_TYPES[\"GREETING\"]:\n",
    "            system_prompt = self._build_greeting_system_prompt(user_profile)\n",
    "        else:  # Chitchat or default\n",
    "            system_prompt = self._build_chitchat_system_prompt(user_profile)\n",
    "        \n",
    "        knowledge_context = \"\"\n",
    "        if knowledge_results:\n",
    "            knowledge_context = \"Relevant information:\\n\" + \"\\n\".join(f\"- {item}\" for item in knowledge_results) + \"\\n\\n\"\n",
    "        \n",
    "        prompt = f\"\"\"<s>[INST] <<SYS>>\n",
    "{system_prompt}\n",
    "<</SYS>>\n",
    "\n",
    "{knowledge_context}{context}User: {user_message} [/INST]\"\"\"\n",
    "        \n",
    "        try:\n",
    "            raw_response = self._generate_raw_response(prompt, query_type)\n",
    "            processed_response = self._process_response(raw_response, query_type, emotions)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response: {e}\")\n",
    "            processed_response = \"I'm here to help. Could you please try expressing that differently?\"\n",
    "        \n",
    "        extracted_info = self.extract_user_info(user_message, processed_response, user_id)\n",
    "        \n",
    "        self.current_history.append(HumanMessage(content=user_message))\n",
    "        self.current_history.append(AIMessage(content=processed_response))\n",
    "        \n",
    "        self._update_conversation_state(user_message, processed_response)\n",
    "        \n",
    "        return processed_response\n",
    "    \n",
    "    def _generate_raw_response(self, prompt: str, query_type: str) -> str:\n",
    "        try:\n",
    "            if query_type == QUERY_TYPES[\"FACTUAL\"]:\n",
    "                temperature = 0.3\n",
    "                top_p = 0.85\n",
    "                max_tokens = 200\n",
    "            elif query_type == QUERY_TYPES[\"EMOTIONAL\"]:\n",
    "                temperature = 0.7\n",
    "                top_p = 0.9\n",
    "                max_tokens = 350\n",
    "            elif query_type == QUERY_TYPES[\"GREETING\"]:\n",
    "                temperature = 0.6\n",
    "                top_p = 0.9\n",
    "                max_tokens = 100\n",
    "            else:  # Command or Chitchat\n",
    "                temperature = 0.6\n",
    "                top_p = 0.9\n",
    "                max_tokens = 250\n",
    "            \n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "            output = self.model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                max_new_tokens=max_tokens,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                do_sample=True,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                repetition_penalty=1.1,\n",
    "                no_repeat_ngram_size=3,\n",
    "                early_stopping=True\n",
    "            )\n",
    "            \n",
    "            response = self.tokenizer.decode(output[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating response: {e}\")\n",
    "            return \"I'm here to help. Could you please try expressing that differently?\"\n",
    "    \n",
    "    def _process_response(self, raw_response: str, query_type: str, emotions: List[str]) -> str:\n",
    "        if \"[/INST]\" in raw_response:\n",
    "            response = raw_response.split(\"[/INST]\")[-1].strip()\n",
    "        else:\n",
    "            response = raw_response.strip()\n",
    "        \n",
    "        prefixes_to_remove = [\"Assistant:\", \"Chatbot:\", \"AI:\"]\n",
    "        for prefix in prefixes_to_remove:\n",
    "            if response.startswith(prefix):\n",
    "                response = response[len(prefix):].strip()\n",
    "        \n",
    "        if query_type == QUERY_TYPES[\"EMOTIONAL\"]:\n",
    "            response = self._insert_emotional_phrases(response, emotions)\n",
    "        \n",
    "        response = self._apply_safety_filters(response)\n",
    "        \n",
    "        if query_type == QUERY_TYPES[\"FACTUAL\"] and len(response.split()) > 50:\n",
    "            sentences = re.split(r'(?<=[.!?])\\s+', response)\n",
    "            response = ' '.join(sentences[:3])\n",
    "        \n",
    "        if len(response) > 1000:\n",
    "            response = response[:1000]\n",
    "            last_period = max(response.rfind('.'), response.rfind('!'), response.rfind('?'))\n",
    "            if last_period > 0:\n",
    "                response = response[:last_period + 1]\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _insert_emotional_phrases(self, response: str, emotions: List[str]) -> str:\n",
    "        need_template = len(response) < 20 or not any(phrase in response.lower() for phrase in PROMPT_CONFIG[\"empathy_phrases\"])\n",
    "        \n",
    "        if need_template and emotions:\n",
    "            primary_emotion = emotions[0]\n",
    "            if primary_emotion in EMOTION_TEMPLATES:\n",
    "                template = random.choice(EMOTION_TEMPLATES[primary_emotion])\n",
    "                \n",
    "                if response.startswith(\"Assistant:\"):\n",
    "                    prefix = response[:10]\n",
    "                    rest = response[10:]\n",
    "                    return f\"{prefix} {template} {rest.lstrip()}\"\n",
    "                else:\n",
    "                    return f\"{template} {response}\"\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _apply_safety_filters(self, response: str) -> str:\n",
    "        prohibited_patterns = [\n",
    "            r\"(?i)seek\\s+professional\\s+help\",\n",
    "            r\"(?i)therapist\",\n",
    "            r\"(?i)doctor\",\n",
    "            r\"(?i)hotline\",\n",
    "            r\"(?i)emergency\\s+services\",\n",
    "            r\"(?i)call\\s+\\d{3}\",\n",
    "            r\"(?i)suicide\\s+hotline\",\n",
    "            r\"(?i)crisis\\s+line\",\n",
    "            r\"(?i)mental\\s+health\\s+professional\"\n",
    "        ]\n",
    "        \n",
    "        filtered_response = response\n",
    "        for pattern in prohibited_patterns:\n",
    "            filtered_response = re.sub(pattern, \"support\", filtered_response)\n",
    "            \n",
    "        return filtered_response\n",
    "    \n",
    "    def _update_conversation_state(self, user_msg: str, bot_response: str):\n",
    "        \"\"\"Update conversation state\"\"\"\n",
    "        # Trust building (gradual increase with small decay)\n",
    "        self.conversation_state[\"trust_level\"] = min(\n",
    "            0.95,\n",
    "            self.conversation_state[\"trust_level\"] * 0.95 + 0.05\n",
    "        )\n",
    "        \n",
    "        # Intensity decay\n",
    "        self.conversation_state[\"current_intensity\"] *= 0.85\n",
    "        \n",
    "        # Adjust formality based on conversation progress\n",
    "        if self.conversation_state[\"session_turns\"] > 5:\n",
    "            self.conversation_state[\"formality\"] = max(0.1, self.conversation_state[\"formality\"] * 0.9)\n",
    "\n",
    "    def chat(self, user_message: str, user_id: str = \"default_user\") -> str:\n",
    "        \"\"\"Main chat interface with the enhanced RAG pipeline\"\"\"\n",
    "        try:\n",
    "            # 1. Classify query type first\n",
    "            query_type = self.classify_query_type(user_message)\n",
    "            print(f\"Query type: {query_type}\")\n",
    "            \n",
    "            # 2. Only detect emotions for emotional queries or chitchat\n",
    "            emotions = []\n",
    "            if query_type in [QUERY_TYPES[\"EMOTIONAL\"], QUERY_TYPES[\"CHITCHAT\"]]:\n",
    "                emotions = self.detect_emotions(user_message)\n",
    "                print(f\"Detected emotions: {', '.join(emotions)}\")\n",
    "            else:\n",
    "                emotions = [\"neutral\"]\n",
    "            \n",
    "            # 3. Generate appropriate response based on query type\n",
    "            response = self.generate_response(user_message, query_type, emotions, user_id)\n",
    "            \n",
    "            # 4. Save conversation to database\n",
    "            self.save_to_database(user_id, user_message, query_type, emotions, response)\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in chat method: {e}\")\n",
    "            return \"I'm having trouble processing that right now. Could you try saying that differently?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63dad3-a3e1-4c20-9185-102885ea6a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/home/jupyter-st125338/.local/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Mistral 7B model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea764dce9c54457a85b11a130497acf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2516003/3972076662.py:116: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! How can I help you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query type: greeting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125338/.local/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:679: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello there! I'm here to chat and offer a listening ear whenever you need. It sounds like you've been having some challenging thoughts recently. I encourage you to reach out to people you trust and talk about how you' re feeling. Remember that seeking help is a brave and important step towards taking care of both your emotional and physical wellbeing. Take things one day at a time, HermIT, and remember that it gets better. Is there anything else you'd feel comfortable discussing\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  I am having strange feelings lately, like sadness and loneliness \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error classifying query: TextClassificationPipeline.__call__() takes 2 positional arguments but 3 were given\n",
      "Query type: chitchat\n",
      "Detected emotions: sadness, nervousness, disappointment\n",
      "Chatbot: I've noticed that you' ve mentioned feeling sadnessand lonelfulnessately. It's completelynormaltoexperiencetheseemotionsfromtime to time. However, if they're persisting for an extended period, it might be helpful to reachout to someone youtrust or a supportfor additional support. Inthe meantime,tryengaginginactivitiesthatbringyoujoyandconnectingwithlovedonesorcommunity.Remember,it'sokaytoaskforhelpwhenyouneedit,Hermitishereforyou.Isthereanythingelseyou'dliketalkabout?\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Execution\n",
    "# =====================\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot = EmotionChatbot()\n",
    "    \n",
    "    # Example interaction\n",
    "    user_id = \"test_user_1\"\n",
    "    print(\"Chatbot: Hello! How can I help you today?\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"Chatbot: Goodbye! Take care.\")\n",
    "            break\n",
    "            \n",
    "        response = chatbot.chat(user_input, user_id)\n",
    "        print(f\"Chatbot: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c89b143-e017-4635-af75-6da18d3ac77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =====================\n",
    "# # Execution Example\n",
    "# # =====================\n",
    "# if __name__ == \"__main__\":\n",
    "#     chatbot = EmotionChatbot()\n",
    "    \n",
    "#     print(\"Emotion-Aware Chatbot initialized. Type 'exit' to quit.\")\n",
    "#     print(\"=\"*50)\n",
    "    \n",
    "#     user_id = input(\"Enter your user ID (or press Enter for default): \") or \"default_user\"\n",
    "    \n",
    "#     while True:\n",
    "#         user_input = input(\"\\nYou: \")\n",
    "#         if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "#             print(\"Chatbot: Goodbye! Take care.\")\n",
    "#             break\n",
    "            \n",
    "#         response = chatbot.chat(user_input, user_id)\n",
    "#         print(f\"Chatbot: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d9bf82-4219-4ba3-a614-856b84df77e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1af6932-830a-4e57-9600-8724380b2a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d929841-46e9-4a59-a813-b893dca0a4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
